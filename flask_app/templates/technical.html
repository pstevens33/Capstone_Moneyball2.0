<head>
  <!-- Latest compiled and minified CSS -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- ************************************   JQuery **************************************** -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/raphael/2.1.2/raphael-min.js"></script>
  <script src="../static/js/kuma-gauge.jquery.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/socket.io/1.3.5/socket.io.min.js"></script>
  <script
  src="https://code.jquery.com/ui/1.12.1/jquery-ui.js"
  integrity="sha256-T0Vest3yCU7pafRw9r+settMBX6JkKN06dqBnpQ8d30="
  crossorigin="anonymous"></script>

  <!-- ************************************   JQuery **************************************** -->

  <!-- ************************************ Bootstrap ************************************ -->

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

  <!-- Optional theme -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">

  <!-- Latest compiled and minified JavaScript -->
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

  <!-- ************************************ Bootstrap   ************************************ -->
  <!-- ************************************   CSS   **************************************** -->

  <link rel="stylesheet" href="{{ url_for('static', filename='styles/base.css') }}">

  <!-- ************************************   CSS   **************************************** -->
  
  <!-- ************************************   Font   **************************************** -->
  
  <link href="https://fonts.googleapis.com/css?family=Slabo+27px" rel="stylesheet">
  
  <!-- ************************************   Font   **************************************** -->
  
  <!-- ************************************   D3   **************************************** -->
  
  <script src="https://d3js.org/d3.v3.min.js"></script>
  <script src="http://labratrevenge.com/d3-tip/javascripts/d3.tip.v0.6.3.js"></script>
  
  <!-- ************************************   D3   **************************************** -->

  <title>Technical</title>
  <style>

  .axis path,
  .axis line {
    fill: none;
    stroke: #000;
    shape-rendering: crispEdges;
  }

  .bar {
    fill: orange;
  }

  .bar:hover {
    fill: orangered ;
  }

  .x.axis path {
    display: none;
  }

  .d3-tip {
    line-height: 1;
    font-weight: bold;
    padding: 12px;
    background: rgba(0, 0, 0, 0.8);
    color: #fff;
    border-radius: 2px;
  }

  /* Creates a small triangle extender for the tooltip */
  .d3-tip:after {
    box-sizing: border-box;
    display: inline;
    font-size: 10px;
    width: 100%;
    line-height: 1;
    color: rgba(0, 0, 0, 0.8);
    content: "\25BC";
    position: absolute;
    text-align: center;
  }

  /* Style northward tooltips differently */
  .d3-tip.n:after {
    margin: -1px 0 0 0;
    top: 100%;
    left: 0;
  }
  </style>
</head>
<br>

{% with messages = get_flashed_messages() %}
  {% if messages %}
    <div class="alert alert-danger">
    {% for message in messages %}
      <center>{{ message }}</center>
    {% endfor %}
    </div>
  {% endif %}
{% endwith %}

<center><h1>Let's Get Technical</h1></center>
<div class="container">
        <br>
        <br>
        <div class="col-sm-2"></div>
        <div class="col-sm-8">
            <div class="pudding-content">
                <p class="pudding-paragraph">
                    I decided to start this project when I was watching the movie "Moneyball" and the scouts kept saying that they projected that some players would be good in the MLB because of their looks. This made me think that maybe there was some truth to this. Or at least a little.
                </p>
                <div id="scout-gif">
                    <center><img src="/static/gif/scout.gif" style="width: 90%;"></center>
                </div>
                <center><p id="dismiss">Click to dismiss</p></center>
                <p class="pudding-paragraph">
                    Since the inception of Major League Baseball in 1871, there have been 19,022 people to play the game. Of that, 13,434 were born in the United States of America and have an obtainable picture of their face. It is important to take only American born players as we are analyzing for facial generalizations and not racially or culturally differentiating characteristics.
                </p>
                <p class="pudding-paragraph">
                    I scraped the image of the 13,434 along with their total WAR stats. WAR stands for "Wins Above Replacement." This is the total number of wins a player produced in his career over what the average player could. Higher WAR = Better Player. Each WAR stat was divided by the number of seasons played to get the average WAR over a career. A WAR of 0 means a player is average, a WAR of 5 means he is a perennial All-Star.
                </p>
                <p class="pudding-paragraph">
                    These images ranged in quality from high-definition headshots to drawings of what may have resembled a face. In order for the model to be able to make predicitons on facial features, I needed to eliminate all of the photos where the computer could not detect a face. A combination of dlib, opencv, and openface were used to detect a face in each image and crop it into a new picture showing just the face.
                </p>
                <center><div style="text-align: center; margin-bottom: 20px;">
                    <img src="static/img/0a3e68ee7b3567f0b3ece8a927f63b7a4de1740c.jpg" alt="Raw Image" style="display: inline-block;">
                    <img src="static/img/arrow.png" alt="Arrow Image" style="width: 50px; height: 50px; margin-left: 20px; margin-right: 20px; display: inline-block;">
                    <img src="static/img/projected_0a3e68ee7b3567f0b3ece8a927f63b7a4de1740c0.jpg" alt="Projected Image" style="display: inline-block;">
                </div></center>
                <p class="pudding-paragraph">
                    This process also helped to account for other factors that could skew the model's predictions. One might have been a team's jersey or hat. I would assume that a model would pick up on the fact that a player wearing a yankees hat is probably better than one sporting an A's cap.
                </p>
                <center><div style="text-align: center; margin-bottom: 20px;">
                    <img src="static/img/0a3e68ee7b3567f0b3ece8a927f63b7a4de1740c.jpg" alt="Raw Image" style="display: inline-block;">
                    <img src="static/img/arrow.png" alt="Arrow Image" style="width: 50px; height: 50px; margin-left: 20px; margin-right: 20px; display: inline-block;">
                    <img src="static/img/projected_0a3e68ee7b3567f0b3ece8a927f63b7a4de1740c0.jpg" alt="Projected Image" style="display: inline-block;">
                </div></center>
                <p class="pudding-paragraph">
                    The processed images were converted into numpy arrays and fed into a convolutional neural network. If you are unclear of how neural nets work, see the image below. At a very high level, they take inputs, make decisions based on a number of factors, and then spit out the output.
                    This process also helped to account for other factors that could skew the model's predictions. One might have been a team's jersey or hat. I would assume that a model would pick up on the fact that a player wearing a yankees hat is probably better than one sporting an A's cap.
                </p>
                <center><div style="text-align: center; margin-bottom: 20px;">
                    <img src="static/img/neural_net_diagram.png" alt="Raw Image" style="display: inline-block;">
                </div></center>
                <p class="pudding-paragraph">
                    The architecture that worked the best for the purpose of this project consisted of 5 convolution layers, each followed by a max pooling layer and dropout layer of 0.35. I also added 4 fully-connected layers to allow for some more depth. The loss function that worked best was binary crossentropy with sigmoid for the output function. I ran the model for 300 epochs and plotted the training and test loss. It should be noted that since the classes were highly imbalanced (68% 0's, 20% 1's, and so on), as the model learned, the accuracy actually went down. Because of the imbalance and the fact that a player's ability isn't driven by facial features to a large extent, as the model begins to guess values other than 0, it is most likely going to become less accurate. The loss was the most important metric to take note of.
                    The processed images were converted into numpy arrays and fed into a convolutional neural network. If you are unclear of how neural nets work, see the image below. At a very high level, they take inputs, make decisions based on a number of factors, and then spit out the output.
                </p>
                <center><div style="text-align: center; margin-bottom: 20px;">
                    <img src="static/img/neural_net_diagram.png" alt="Raw Image" style="display: inline-block;">
                </div></center>
                <p class="pudding-paragraph">
                    The architecture that worked the best for the purpose of this project consisted of 5 convolution layers, each followed by a max pooling layer and dropout layer of 0.35. I also added 4 fully-connected layers to allow for some more depth. The loss function that worked best was binary crossentropy with sigmoid for the output function. I ran the model for 300 epochs and plotted the training and test loss. It should be noted that since the classes were highly imbalanced (60% 0's, 20% 1's, and so on), as the model learned, the accuracy actually went down. Because of the imbalance and the fact that a player's ability isn't driven by facial features to a large extent, as the model begins to guess values other than 0, it is most likely going to become less accurate. The loss was the most important metric to take note of.
                </p>
                <center><div style="text-align: center; margin-bottom: 20px;">
                    <img src="static/img/loss_300_binary_sigmoid_adam_0.35.png" alt="Raw Image" style="display: inline-block;">
                </div></center>
                <p class="pudding-paragraph">
                    You can see that the test loss continues to decrease until around the 60th epoch. The training loss decreases continually with a dropout set at 0.35. Less dropout resulted in a terrible test loss and higher dropout increased the time to convergence significantly.
                </p>
                <p class="pudding-paragraph">
                    So what does this neural network tell us?
                </p>
                <p class="pudding-paragraph large-text">
                    THE SCOUTS WERE RIGHT...sort of.
                </p>
                <p class="pudding-paragraph">
                    The images were split up into folders dedicated to their respective classes, i.e. the pictures of players with a WAR of 0 went into a certain folder, WARs of 1's went in another, and so on. The model then made its predictions on each folder. The hope was that it would predict 0's for every picture in the "0 folder" up to 5's for every picture in the "5 folder." The average prediction for each class is recorded below. You can see how the model actually predicts higher values for the higher classes.
                </p>
                <center><svg id="svg-trend" style="width: 100%"></svg></center>
                <p class="pudding-paragraph">
                    So the model can't see a 5 and predict 5. That's a given. But the trend shown explains that even on unseen data, the model predicts higher values for better players.
                </p>
                <p class="pudding-paragraph large-text">
                    Try uploading a picture of your own to see what the neural net thinks of you.
                </p>
                <center>
                    <form action="/score" method="POST" enctype="multipart/form-data" id="submit-form" role="form">
                        <input type="file" name="file"><br /><br />
                        <input id="submit-button" type="submit" value="Upload">
                    </form>
                    <div id="loadingDiv">
                        <center><h2>Sit tight, we're predicting your success</h2></center>
                        <center><img id="spinning-ball" src="/static/gif/spinning-baseball.gif"></center>
                    </div>
                </center>
                
                <center>
                    <div class="js-gauge demo gauge" id="score-gauge-0"></div>
                    <div class="js-gauge demo gauge" id="score-gauge-1"></div>
                    <div class="js-gauge demo gauge" id="score-gauge-2"></div>
                    <div class="js-gauge demo gauge" id="score-gauge-3"></div>
                    <div class="js-gauge demo gauge" id="score-gauge-4"></div>
                    <div class="js-gauge demo gauge" id="score-gauge-5"></div>
                    <div class="js-gauge demo gauge" id="score-gauge-6"></div>
                    <div class="js-gauge demo gauge" id="score-gauge-7"></div>
                    <div class="js-gauge demo gauge" id="score-gauge-8"></div>
                    <div class="js-gauge demo gauge" id="score-gauge-9"></div>
                    <div class="js-gauge demo gauge" id="score-gauge-10"></div>
                    
                    
                    <div id="hidden-pic">
                        <p>Based on your projected face.</p>
                        <img id="projected-image" src='/static/img/white_square.png' alt="Projected Image">
                        <br>
                        <br>
                        <input id="reset-button" type="submit" value="Try Again">
                    </div>
                </center>

                <p class="pudding-paragraph">
                    The next step is to determine what features make our model predict who's good and who's not. I thought the best way to do that would be to visualize the filters. Let me explain how this is done... The images that are fed into the model have a very high amount of loss. The loss is reduced by gradient descent with respect to the cost function associated with the data. The picture is broken down piece by piece and the neural net learns the bits that make up the data. To visualize the filters you can think of the reverse of this process. You start with an output class, let's use 0, and feed a noisy image (think bad reception on a 1950s television) into the model. The model will employ gradient ASCENT in order to maximize the loss of the cost function. Each iteration of gradient ascent, the loss will increase and a picture representing what the model thinks to be a 0 will begin to take shape. Perfect in theory. Below is the output of a picture that the model is 99.9% certain to belong to the class 0.
                </p>
                <center><div style="text-align: center; margin-bottom: 20px;">
                    <img src="static/img/max_0_GPU_500_idkwhatloss_32x32x64x64x128.png" alt="Raw Image" style="display: inline-block;">
                </div></center>
                <p class="pudding-paragraph">
                    It doesn't look as human as I was hoping. This is because the model does not process images the same way you and I do. Either way, there is another way to visualize the differences in class facial features.
                </p>
                <p class="pudding-paragraph">
                    If all of the faces of each class could be averaged together, maybe we could see the differences using human inference. The problem with this strategy is that there are over 9000 images in the 0 class. Each image is of size 128x128, meaning that there are 16384 possible dimensions for each picture. This sounds like a prefect time to employ <strong>Principal Component Analysis</strong>. PCA involves reducing the dimensionality of the input data. Coupled with eigenfaces, a series of eigenvectors that resembe human faces, the images could be broken down into the dimensions that were truly critical in representing the face. By doing this, we can average the pictures of each class and note differences between them. The pictures below are the actual average faces calculated from all of the pictures in each class, 0 to 5, from left to right.
                </p>
                <center>
                        <img class="eigen-pics" src='../static/img/average_0.png' alt='Average Face 0'>
                        <img class="eigen-pics" src='../static/img/average_1.png' alt='Average Face 1'>
                        <img class="eigen-pics" src='../static/img/average_2.png' alt='Average Face 2'>
                        <img class="eigen-pics" src='../static/img/average_3.png' alt='Average Face 3'>
                        <img class="eigen-pics" src='../static/img/average_4.png' alt='Average Face 4'>
                        <img class="eigen-pics" src='../static/img/average_5.png' alt='Average Face 5'>
                </center>
                <br>
                <p class="pudding-paragraph">
                    It seems as though class 5 (right picture) has a more serious demeanor than the others. Classes 0 and 1 sport rounder faces and softer features. And maybe the scratchy texture around the chin of 4 and 5 show an affinity for facial hair. Do you agree or disagree? I'm curious to hear what y'all think so leave a comment and let me know!
                </p>
                <p class="pudding-paragraph">
                    Amazingly enough, since these pictures were an accumulation of pictures that the model trained on, you can plug these pictures into the prediction model and see that they predict in ascending order! Even though the faces look very similar, the model can detect the small differences and make accurate predictions.
                </p>
                <hr>
                <div id="log"></div>
                <div id="hidden-size"></div>
                
                
            </div>
        </div>
        <div class="col-sm-2"></div>
</div>

<script>
var upload_count = 0;

$SCRIPT_ROOT = {{ request.script_root|tojson|safe }};


var margin = {top: 40, right: 20, bottom: 30, left: 40},
    width = screen.width/3.5 + $('#hidden-size').width() - margin.left - margin.right,
    height = screen.height/2 - margin.bottom;

var formatPercent = d3.format("");

var x = d3.scale.ordinal()
    .rangeRoundBands([0, width], .1);

var y = d3.scale.linear()
    .range([height, 0]);

var xAxis = d3.svg.axis()
    .scale(x)
    .orient("bottom");

var yAxis = d3.svg.axis()
    .scale(y)
    .orient("left")
    .tickFormat(formatPercent);

var tip = d3.tip()
  .attr('class', 'd3-tip')
  .offset([-10, 0])
  .html(function(d) {
    return "<strong>average:</strong> <span style='color:red'>" + d.average + "</span>";
  })

var svg = d3.select("svg")
    .attr("width", width + margin.left + margin.right)
    .attr("height", height + margin.top + margin.bottom)
  .append("g")
    .attr("transform", "translate(" + margin.left + "," + margin.top + ")");

svg.call(tip);

d3.csv("/endpoint", type, function(error, data) {
  x.domain(data.map(function(d) { return d.class; }));
  y.domain([0, d3.max(data, function(d) { return d.average; })]);

  svg.append("g")
      .attr("class", "x axis")
      .attr("transform", "translate(0," + height + ")")
      .call(xAxis);

  svg.append("g")
      .attr("class", "y axis")
      .call(yAxis)
    .append("text")
      .attr("transform", "rotate(-90)")
      .attr("y", 6)
      .attr("dy", ".71em")
      .style("text-anchor", "end")
      .text("Average");

  svg.selectAll(".bar")
      .data(data)
    .enter().append("rect")
      .attr("class", "bar")
      .attr("x", function(d) { return x(d.class); })
      .attr("width", x.rangeBand())
      .attr("y", function(d) { return y(d.average); })
      .attr("height", function(d) { return height - y(d.average); })
      .on('mouseover', tip.show)
      .on('mouseout', tip.hide)

});

function type(d) {
  d.average = +d.average;
  return d;
}

$('#loadingDiv').hide();
$('#hidden-pic').hide();

$("#submit-button").click(function(){
    $("#spinning-ball").attr('src', "/static/gif/spinning-baseball.gif?"+ Math.random());
    $('#submit-form').hide();
    $('#loadingDiv').show();
    $.ajax({
        url: "/wait",
        type: "POST",
        processData: false,
        contentType: false,
    }).done(function(){
      console.log("Success: Files sent!");

        $.getJSON('/read_json', function(json) {
            $('#loadingDiv').hide();
            $("#projected-image").attr("src","../projected_faces_web/" + json['path']);
            $('.demo#score-gauge-'+upload_count).kumaGauge({
              value : json['score'],
              animationSpeed : 1000,
              showNeedle : false,
              // background : '#4EA9D7',
              label : {
                  display: true,
                  left: '0',
                  right: '100',
                  fontColor : '#E31E81',
                  fontSize : 16,
              }
            });
        $("#hidden-pic").show();
        });
    }).fail(function(){
      console.log("An error occurred, the files couldn't be sent!");
    });
});

$("#reset-button").click(function(){
    $("#gauge-0").remove();
    // $('.demo').replace();
    $("#hidden-pic").hide();
    $('#submit-form').show();
    $("#projected-image").attr('src', "/static/img/white_square.png")
    upload_count++;
    if(upload_count >= 9) {
        location.reload();
    }
});

$("#scout-gif").click(function(){
    this.remove();
    $("#dismiss").hide();
});

$("#dismiss").click(function(){
    this.remove();
    $("#scout-gif").remove();
});


</script>